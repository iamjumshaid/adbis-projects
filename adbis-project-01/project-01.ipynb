{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67aa9892-2eff-4949-abd9-150f30712829",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Advanced Databases and Information Systems Project I</span>\n",
    "## Programming with Spark RDD and DataFrame\n",
    "\n",
    "**Group Members**:\n",
    "* Omar Swelam os132@uni-freiburg.de\n",
    "* Jumshaid Khan jk1308@uni-freiburg.de\n",
    "\n",
    "**Submitted to**: \n",
    "Dr. Fang Wei-Kleiner\n",
    "\n",
    "**Repository:** https://github.com/iamjumshaid/adbis-projects\n",
    "\n",
    "**<span style=\"color:red\">Note:</span>** We have added your email `fwei@informatik.uni-freiburg.de` as collaborator to our private GitHub repository.\n",
    "\n",
    "**References**:\n",
    "* https://sparkbyexamples.com/pyspark/pyspark-map-transformation/\n",
    "* https://sparkbyexamples.com/pyspark/pyspark-count/\n",
    "* https://sparkbyexamples.com/pyspark/pyspark-explode-nested-array-into-rows/\n",
    "* https://chat.openai.com/ [Used for understanding concepts, code optimisations, and pair programming]\n",
    "* https://bard.google.com/ [Used for understanding concepts, code optimisations, and pair programming]\n",
    "  \n",
    "**Date:** 30.07.2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b2ff871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56434db",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Task 1.2 (Loading the dataset into an RDD)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f53549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring Spark\n",
    "# Created a SparkConf object, named the application, run Spark on 3 local cores, with executor memory of 12 GB and driver memory of 8 GB\n",
    "conf = SparkConf().setAppName(\"LocalSparkCluster\").setMaster(\"local[3]\")\n",
    "conf.set(\"spark.executor.memory\", \"12g\")\n",
    "conf.set(\"spark.driver.memory\", \"8g\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267cd371",
   "metadata": {},
   "source": [
    "**a) userRatingsRDD: creating a pair RDD from user 'libraries.txt' using the `user hash` as the key and the liked\n",
    "paper(s) `paper_id` as the value(s).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1dec417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('28d3f81251d94b09735497477a5e4e02',\n",
       "  ['5984302',\n",
       "   '3481823',\n",
       "   '4636156',\n",
       "   '635215',\n",
       "   '3929762',\n",
       "   '4810441',\n",
       "   '503574',\n",
       "   '4194836',\n",
       "   '5490453',\n",
       "   '3366480',\n",
       "   '5996865',\n",
       "   '462949',\n",
       "   '5828780',\n",
       "   '4450195',\n",
       "   '4165233',\n",
       "   '635216',\n",
       "   '5819422',\n",
       "   '4238883',\n",
       "   '5788061',\n",
       "   '4238942']),\n",
       " ('d0c9aaa788153daeaf1f1538b3d46bbb',\n",
       "  ['5761055',\n",
       "   '4226226',\n",
       "   '5184704',\n",
       "   '5760287',\n",
       "   '226864',\n",
       "   '913868',\n",
       "   '3466838',\n",
       "   '8806369',\n",
       "   '2363430',\n",
       "   '3281547',\n",
       "   '4781370',\n",
       "   '239571',\n",
       "   '6614346',\n",
       "   '5441098',\n",
       "   '2080691',\n",
       "   '1805577',\n",
       "   '853030',\n",
       "   '3512183',\n",
       "   '4089758',\n",
       "   '2855355',\n",
       "   '3140015',\n",
       "   '2445106',\n",
       "   '4236212',\n",
       "   '5687747',\n",
       "   '678653',\n",
       "   '1959511',\n",
       "   '2841637',\n",
       "   '767516',\n",
       "   '7562861',\n",
       "   '2049617',\n",
       "   '6607628',\n",
       "   '7570111',\n",
       "   '12571584',\n",
       "   '2653863',\n",
       "   '6343346',\n",
       "   '1012525',\n",
       "   '2688186',\n",
       "   '5336762',\n",
       "   '1277953',\n",
       "   '4140337',\n",
       "   '7756088',\n",
       "   '3190274',\n",
       "   '2782576',\n",
       "   '311570',\n",
       "   '2080631']),\n",
       " ('f05bcffe7951de9e5a32fff4a42eb088',\n",
       "  ['781057',\n",
       "   '1055600',\n",
       "   '579614',\n",
       "   '5177766',\n",
       "   '5201306',\n",
       "   '129',\n",
       "   '706033',\n",
       "   '10362464',\n",
       "   '336911',\n",
       "   '227096',\n",
       "   '7623038',\n",
       "   '99',\n",
       "   '1784935',\n",
       "   '13207613',\n",
       "   '1320137',\n",
       "   '878326',\n",
       "   '1218954',\n",
       "   '827938',\n",
       "   '239',\n",
       "   '949352',\n",
       "   '507529',\n",
       "   '405672',\n",
       "   '671699',\n",
       "   '478707',\n",
       "   '151946',\n",
       "   '255030',\n",
       "   '12938139',\n",
       "   '6305290',\n",
       "   '9946377',\n",
       "   '714977',\n",
       "   '1959297',\n",
       "   '7357993',\n",
       "   '3459771',\n",
       "   '13687046',\n",
       "   '1160828',\n",
       "   '9983047',\n",
       "   '8423325',\n",
       "   '407124',\n",
       "   '3317637',\n",
       "   '423698',\n",
       "   '3956160',\n",
       "   '144287',\n",
       "   '1814546',\n",
       "   '3129258',\n",
       "   '1325105',\n",
       "   '6475030',\n",
       "   '11597926',\n",
       "   '3578102',\n",
       "   '3726797',\n",
       "   '10138849',\n",
       "   '12901647',\n",
       "   '9001253',\n",
       "   '781055',\n",
       "   '9396734',\n",
       "   '12937120',\n",
       "   '12037219',\n",
       "   '13329593',\n",
       "   '1321106',\n",
       "   '12054725',\n",
       "   '921623',\n",
       "   '1835552',\n",
       "   '3748163',\n",
       "   '10045309',\n",
       "   '1119267',\n",
       "   '13408130',\n",
       "   '682116',\n",
       "   '876703',\n",
       "   '802634',\n",
       "   '4488840',\n",
       "   '12394780',\n",
       "   '11923443',\n",
       "   '3112352',\n",
       "   '622633',\n",
       "   '9172127',\n",
       "   '5102465',\n",
       "   '1405472',\n",
       "   '247',\n",
       "   '5664256',\n",
       "   '921399',\n",
       "   '553840',\n",
       "   '4492925',\n",
       "   '12735311',\n",
       "   '10098153',\n",
       "   '11191048',\n",
       "   '494336',\n",
       "   '230211',\n",
       "   '2308256',\n",
       "   '556147',\n",
       "   '12716731',\n",
       "   '13329754',\n",
       "   '920055',\n",
       "   '6792520',\n",
       "   '1036492',\n",
       "   '166220',\n",
       "   '1426283',\n",
       "   '11536389',\n",
       "   '1825619',\n",
       "   '8493138',\n",
       "   '12788583',\n",
       "   '882809',\n",
       "   '9081047',\n",
       "   '10462916',\n",
       "   '4448813',\n",
       "   '2945819',\n",
       "   '12790816',\n",
       "   '9478785',\n",
       "   '525396',\n",
       "   '6196237',\n",
       "   '12796779',\n",
       "   '968854',\n",
       "   '8217163',\n",
       "   '1153421',\n",
       "   '12925513',\n",
       "   '137486',\n",
       "   '742892',\n",
       "   '11852474',\n",
       "   '9069826',\n",
       "   '11839662',\n",
       "   '988447',\n",
       "   '1769635',\n",
       "   '9445526',\n",
       "   '3044720',\n",
       "   '6531882',\n",
       "   '12732269',\n",
       "   '261290',\n",
       "   '7355647',\n",
       "   '1158654',\n",
       "   '2097471',\n",
       "   '11847579',\n",
       "   '12738996',\n",
       "   '703464',\n",
       "   '6670515',\n",
       "   '3281478',\n",
       "   '7538620',\n",
       "   '213068',\n",
       "   '1467354',\n",
       "   '833638',\n",
       "   '504896',\n",
       "   '5413529',\n",
       "   '945310',\n",
       "   '2705980',\n",
       "   '72879',\n",
       "   '80543',\n",
       "   '2945839',\n",
       "   '503161',\n",
       "   '488726',\n",
       "   '556149',\n",
       "   '6486855',\n",
       "   '6982661',\n",
       "   '942241',\n",
       "   '3856997',\n",
       "   '622635',\n",
       "   '10685085',\n",
       "   '1453872',\n",
       "   '2862386',\n",
       "   '7154210',\n",
       "   '6595566',\n",
       "   '1649749',\n",
       "   '2242776',\n",
       "   '7804574',\n",
       "   '4027225',\n",
       "   '10802130',\n",
       "   '1320157',\n",
       "   '2825',\n",
       "   '100186',\n",
       "   '227173',\n",
       "   '3733678',\n",
       "   '2783692',\n",
       "   '10723139',\n",
       "   '2121165']),\n",
       " ('ca4f1ba4094011d9a8757b1bfcadae5b', ['278019']),\n",
       " ('d1d41a152019155035ceb2db7d331c44',\n",
       "  ['3105791',\n",
       "   '6610569',\n",
       "   '6609079',\n",
       "   '7364933',\n",
       "   '7499794',\n",
       "   '6610585',\n",
       "   '7364971',\n",
       "   '6609240',\n",
       "   '6609169',\n",
       "   '7363526',\n",
       "   '6609245',\n",
       "   '7329626',\n",
       "   '7427963',\n",
       "   '6609238',\n",
       "   '7364823',\n",
       "   '7364976',\n",
       "   '7499801',\n",
       "   '6743243',\n",
       "   '7363498',\n",
       "   '7465494',\n",
       "   '7363513',\n",
       "   '7363487',\n",
       "   '7339380',\n",
       "   '7364990',\n",
       "   '1391614',\n",
       "   '6493797',\n",
       "   '7499869',\n",
       "   '7499833',\n",
       "   '7364973',\n",
       "   '7469738',\n",
       "   '6609099',\n",
       "   '7364987',\n",
       "   '7469728',\n",
       "   '7469737',\n",
       "   '1153734',\n",
       "   '7363519',\n",
       "   '7241881',\n",
       "   '7364991',\n",
       "   '7364986',\n",
       "   '1397150',\n",
       "   '6609222',\n",
       "   '6609102'])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Read the text file and create an RDD of lines, e.g. ['28d3f81251d94b09735497477a5e4e02;3929762,503574,5819422,4238883,5788061,46294', ...]\n",
    "users_papers_rdd = sc.textFile(\"users_libraries.txt\")\n",
    "\n",
    "# Split the `users_papers_rdd` on the basis of ';' criteria using the map() transformation\n",
    "# Maps the `users_papers_rdd` lines to [('28d3f81251d94b09735497477a5e4e02', ['3929762', '503574', '5819422', '4238883'], ...)]\n",
    "users_rdd = users_papers_rdd.map(lambda line: line.split(\";\")).map(lambda x: (x[0], x[1].split(\",\")))\n",
    "\n",
    "# The papers are now stored as a set instead of a list using the `mapValues()` transformation and caching the transformation in memory so it's not recomputed every time.\n",
    "split_users_rdd = users_rdd.mapValues(lambda x: list(set(x))).cache()\n",
    "\n",
    "end_time =time.time()\n",
    "\n",
    "split_users_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe2e85cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in creating the pair RDD from user `libraries.txt`: 0.08 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Time taken in creating the pair RDD from user `libraries.txt`: %.2f seconds' % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e0f075",
   "metadata": {},
   "source": [
    "**b) paperTermsRDD: creating a pair RDD from 'papers.csv' using the `paper_id` as the key and the words contained in the abstract as the value(s).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fad009e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('80546',\n",
       "  ['the',\n",
       "   'genetic',\n",
       "   'code',\n",
       "   'has',\n",
       "   'been',\n",
       "   'regarded',\n",
       "   'as',\n",
       "   'arbitrary',\n",
       "   'in',\n",
       "   'the',\n",
       "   'sense',\n",
       "   'that',\n",
       "   'the',\n",
       "   'codon',\n",
       "   'amino',\n",
       "   'acid',\n",
       "   'assignments',\n",
       "   'could',\n",
       "   'be',\n",
       "   'different',\n",
       "   'than',\n",
       "   'they',\n",
       "   'actually',\n",
       "   'are',\n",
       "   'this',\n",
       "   'general',\n",
       "   'idea',\n",
       "   'has',\n",
       "   'been',\n",
       "   'spelled',\n",
       "   'out',\n",
       "   'differently',\n",
       "   'by',\n",
       "   'previous',\n",
       "   'often',\n",
       "   'rather',\n",
       "   'implicit',\n",
       "   'accounts',\n",
       "   'of',\n",
       "   'arbitrariness',\n",
       "   'they',\n",
       "   'have',\n",
       "   'drawn',\n",
       "   'on',\n",
       "   'the',\n",
       "   'frozen',\n",
       "   'accident',\n",
       "   'theory',\n",
       "   'on',\n",
       "   'evolutionary',\n",
       "   'contingency',\n",
       "   'on',\n",
       "   'alternative',\n",
       "   'causal',\n",
       "   'pathways',\n",
       "   'and',\n",
       "   'on',\n",
       "   'the',\n",
       "   'absence',\n",
       "   'of',\n",
       "   'direct',\n",
       "   'stereochemical',\n",
       "   'interactions',\n",
       "   'between',\n",
       "   'codons',\n",
       "   'and',\n",
       "   'amino',\n",
       "   'acids',\n",
       "   'it',\n",
       "   'has',\n",
       "   'also',\n",
       "   'been',\n",
       "   'suggested',\n",
       "   'that',\n",
       "   'the',\n",
       "   'arbitrariness',\n",
       "   'of',\n",
       "   'the',\n",
       "   'genetic',\n",
       "   'code',\n",
       "   'justifies',\n",
       "   'attributing',\n",
       "   'semantic',\n",
       "   'information',\n",
       "   'to',\n",
       "   'macromolecules',\n",
       "   'notably',\n",
       "   'to',\n",
       "   'dna',\n",
       "   'i',\n",
       "   'argue',\n",
       "   'that',\n",
       "   'these',\n",
       "   'accounts',\n",
       "   'of',\n",
       "   'arbitrariness',\n",
       "   'are',\n",
       "   'unsatisfactory',\n",
       "   'i',\n",
       "   'propose',\n",
       "   'that',\n",
       "   'the',\n",
       "   'code',\n",
       "   'is',\n",
       "   'arbitrary',\n",
       "   'in',\n",
       "   'the',\n",
       "   'sense',\n",
       "   'of',\n",
       "   'jacques',\n",
       "   'monod',\n",
       "   's',\n",
       "   'concept',\n",
       "   'of',\n",
       "   'chemical',\n",
       "   'the',\n",
       "   'genetic',\n",
       "   'code',\n",
       "   'is',\n",
       "   'arbitrary',\n",
       "   'in',\n",
       "   'that',\n",
       "   'any',\n",
       "   'codon',\n",
       "   'requires',\n",
       "   'certain',\n",
       "   'chemical',\n",
       "   'and',\n",
       "   'structural',\n",
       "   'properties',\n",
       "   'to',\n",
       "   'specify',\n",
       "   'a',\n",
       "   'particular',\n",
       "   'amino',\n",
       "   'acid',\n",
       "   'but',\n",
       "   'these',\n",
       "   'properties',\n",
       "   'are',\n",
       "   'not',\n",
       "   'required',\n",
       "   'in',\n",
       "   'virtue',\n",
       "   'of',\n",
       "   'a',\n",
       "   'principle',\n",
       "   'of',\n",
       "   'chemistry',\n",
       "   'this',\n",
       "   'notion',\n",
       "   'of',\n",
       "   'arbitrariness',\n",
       "   'is',\n",
       "   'compatible',\n",
       "   'with',\n",
       "   'several',\n",
       "   'recent',\n",
       "   'hypotheses',\n",
       "   'about',\n",
       "   'code',\n",
       "   'evolution',\n",
       "   'i',\n",
       "   'maintain',\n",
       "   'that',\n",
       "   'the',\n",
       "   'code',\n",
       "   's',\n",
       "   'chemical',\n",
       "   'arbitrariness',\n",
       "   'is',\n",
       "   'neither',\n",
       "   'sufficient',\n",
       "   'nor',\n",
       "   'necessary',\n",
       "   'for',\n",
       "   'attributing',\n",
       "   'semantic',\n",
       "   'information',\n",
       "   'to',\n",
       "   'nucleic',\n",
       "   'acids']),\n",
       " ('5842862',\n",
       "  ['choosing',\n",
       "   'good',\n",
       "   'problems',\n",
       "   'is',\n",
       "   'essential',\n",
       "   'for',\n",
       "   'being',\n",
       "   'a',\n",
       "   'good',\n",
       "   'scientist',\n",
       "   'but',\n",
       "   'what',\n",
       "   'is',\n",
       "   'a',\n",
       "   'good',\n",
       "   'problem',\n",
       "   'and',\n",
       "   'how',\n",
       "   'do',\n",
       "   'you',\n",
       "   'choose',\n",
       "   'one',\n",
       "   'the',\n",
       "   'subject',\n",
       "   'is',\n",
       "   'not',\n",
       "   'usually',\n",
       "   'discussed',\n",
       "   'explicitly',\n",
       "   'within',\n",
       "   'our',\n",
       "   'profession',\n",
       "   'scientists',\n",
       "   'are',\n",
       "   'expected',\n",
       "   'to',\n",
       "   'be',\n",
       "   'smart',\n",
       "   'enough',\n",
       "   'to',\n",
       "   'figure',\n",
       "   'it',\n",
       "   'out',\n",
       "   'on',\n",
       "   'their',\n",
       "   'own',\n",
       "   'and',\n",
       "   'through',\n",
       "   'the',\n",
       "   'observation',\n",
       "   'of',\n",
       "   'their',\n",
       "   'teachers',\n",
       "   'this',\n",
       "   'lack',\n",
       "   'of',\n",
       "   'explicit',\n",
       "   'discussion',\n",
       "   'leaves',\n",
       "   'a',\n",
       "   'vacuum',\n",
       "   'that',\n",
       "   'can',\n",
       "   'lead',\n",
       "   'to',\n",
       "   'approaches',\n",
       "   'such',\n",
       "   'as',\n",
       "   'choosing',\n",
       "   'problems',\n",
       "   'that',\n",
       "   'can',\n",
       "   'give',\n",
       "   'results',\n",
       "   'that',\n",
       "   'merit',\n",
       "   'publication',\n",
       "   'in',\n",
       "   'valued',\n",
       "   'journals',\n",
       "   'resulting',\n",
       "   'in',\n",
       "   'a',\n",
       "   'job',\n",
       "   'and',\n",
       "   'tenure']),\n",
       " ('1242600',\n",
       "  ['although',\n",
       "   'scientists',\n",
       "   'typically',\n",
       "   'insist',\n",
       "   'that',\n",
       "   'their',\n",
       "   'research',\n",
       "   'is',\n",
       "   'very',\n",
       "   'exciting',\n",
       "   'and',\n",
       "   'adventurous',\n",
       "   'when',\n",
       "   'they',\n",
       "   'talk',\n",
       "   'to',\n",
       "   'laymen',\n",
       "   'and',\n",
       "   'prospective',\n",
       "   'students',\n",
       "   'the',\n",
       "   'allure',\n",
       "   'of',\n",
       "   'this',\n",
       "   'enthusiasm',\n",
       "   'is',\n",
       "   'too',\n",
       "   'often',\n",
       "   'lost',\n",
       "   'in',\n",
       "   'the',\n",
       "   'predictable',\n",
       "   'stilted',\n",
       "   'structure',\n",
       "   'and',\n",
       "   'language',\n",
       "   'of',\n",
       "   'their',\n",
       "   'scientific',\n",
       "   'publications',\n",
       "   'i',\n",
       "   'present',\n",
       "   'here',\n",
       "   'a',\n",
       "   'top',\n",
       "   'list',\n",
       "   'of',\n",
       "   'recommendations',\n",
       "   'for',\n",
       "   'how',\n",
       "   'to',\n",
       "   'write',\n",
       "   'consistently',\n",
       "   'boring',\n",
       "   'scientific',\n",
       "   'publications',\n",
       "   'i',\n",
       "   'then',\n",
       "   'discuss',\n",
       "   'why',\n",
       "   'we',\n",
       "   'should',\n",
       "   'and',\n",
       "   'how',\n",
       "   'we',\n",
       "   'could',\n",
       "   'make',\n",
       "   'these',\n",
       "   'contributions',\n",
       "   'more',\n",
       "   'accessible',\n",
       "   'and',\n",
       "   'exciting']),\n",
       " ('3467077',\n",
       "  ['many',\n",
       "   'scientists',\n",
       "   'now',\n",
       "   'manage',\n",
       "   'the',\n",
       "   'bulk',\n",
       "   'of',\n",
       "   'their',\n",
       "   'bibliographic',\n",
       "   'information',\n",
       "   'electronically',\n",
       "   'thereby',\n",
       "   'organizing',\n",
       "   'their',\n",
       "   'publications',\n",
       "   'and',\n",
       "   'citation',\n",
       "   'material',\n",
       "   'from',\n",
       "   'digital',\n",
       "   'libraries',\n",
       "   'however',\n",
       "   'a',\n",
       "   'library',\n",
       "   'has',\n",
       "   'been',\n",
       "   'described',\n",
       "   'as',\n",
       "   'in',\n",
       "   'cold',\n",
       "   'storage',\n",
       "   'and',\n",
       "   'unfortunately',\n",
       "   'many',\n",
       "   'digital',\n",
       "   'libraries',\n",
       "   'can',\n",
       "   'be',\n",
       "   'cold',\n",
       "   'impersonal',\n",
       "   'isolated',\n",
       "   'and',\n",
       "   'inaccessible',\n",
       "   'places',\n",
       "   'in',\n",
       "   'this',\n",
       "   'review',\n",
       "   'we',\n",
       "   'discuss',\n",
       "   'the',\n",
       "   'current',\n",
       "   'chilly',\n",
       "   'state',\n",
       "   'of',\n",
       "   'digital',\n",
       "   'libraries',\n",
       "   'for',\n",
       "   'the',\n",
       "   'computational',\n",
       "   'biologist',\n",
       "   'including',\n",
       "   'pubmed',\n",
       "   'ieee',\n",
       "   'xplore',\n",
       "   'the',\n",
       "   'acm',\n",
       "   'digital',\n",
       "   'library',\n",
       "   'isi',\n",
       "   'web',\n",
       "   'of',\n",
       "   'knowledge',\n",
       "   'scopus',\n",
       "   'citeseer',\n",
       "   'arxiv',\n",
       "   'dblp',\n",
       "   'and',\n",
       "   'google',\n",
       "   'scholar',\n",
       "   'we',\n",
       "   'illustrate',\n",
       "   'the',\n",
       "   'current',\n",
       "   'process',\n",
       "   'of',\n",
       "   'using',\n",
       "   'these',\n",
       "   'libraries',\n",
       "   'with',\n",
       "   'a',\n",
       "   'typical',\n",
       "   'workflow',\n",
       "   'and',\n",
       "   'highlight',\n",
       "   'problems',\n",
       "   'with',\n",
       "   'managing',\n",
       "   'data',\n",
       "   'and',\n",
       "   'metadata',\n",
       "   'using',\n",
       "   'uris',\n",
       "   'we',\n",
       "   'then',\n",
       "   'examine',\n",
       "   'a',\n",
       "   'range',\n",
       "   'of',\n",
       "   'new',\n",
       "   'applications',\n",
       "   'such',\n",
       "   'as',\n",
       "   'zotero',\n",
       "   'mendeley',\n",
       "   'mekentosj',\n",
       "   'papers',\n",
       "   'myncbi',\n",
       "   'citeulike',\n",
       "   'connotea',\n",
       "   'and',\n",
       "   'hubmed',\n",
       "   'that',\n",
       "   'exploit',\n",
       "   'the',\n",
       "   'web',\n",
       "   'to',\n",
       "   'make',\n",
       "   'these',\n",
       "   'digital',\n",
       "   'libraries',\n",
       "   'more',\n",
       "   'personal',\n",
       "   'sociable',\n",
       "   'integrated',\n",
       "   'and',\n",
       "   'accessible',\n",
       "   'places',\n",
       "   'we',\n",
       "   'conclude',\n",
       "   'with',\n",
       "   'how',\n",
       "   'these',\n",
       "   'applications',\n",
       "   'may',\n",
       "   'begin',\n",
       "   'to',\n",
       "   'help',\n",
       "   'achieve',\n",
       "   'a',\n",
       "   'digital',\n",
       "   'defrost',\n",
       "   'and',\n",
       "   'discuss',\n",
       "   'some',\n",
       "   'of',\n",
       "   'the',\n",
       "   'issues',\n",
       "   'that',\n",
       "   'will',\n",
       "   'help',\n",
       "   'or',\n",
       "   'hinder',\n",
       "   'this',\n",
       "   'in',\n",
       "   'terms',\n",
       "   'of',\n",
       "   'making',\n",
       "   'libraries',\n",
       "   'on',\n",
       "   'the',\n",
       "   'web',\n",
       "   'warmer',\n",
       "   'places',\n",
       "   'in',\n",
       "   'the',\n",
       "   'future',\n",
       "   'becoming',\n",
       "   'resources',\n",
       "   'that',\n",
       "   'are',\n",
       "   'considerably',\n",
       "   'more',\n",
       "   'useful',\n",
       "   'to',\n",
       "   'both',\n",
       "   'humans',\n",
       "   'and',\n",
       "   'machines']),\n",
       " ('309395',\n",
       "  ['there',\n",
       "   'is',\n",
       "   'increasing',\n",
       "   'concern',\n",
       "   'that',\n",
       "   'most',\n",
       "   'current',\n",
       "   'published',\n",
       "   'research',\n",
       "   'findings',\n",
       "   'are',\n",
       "   'false',\n",
       "   'the',\n",
       "   'probability',\n",
       "   'that',\n",
       "   'a',\n",
       "   'research',\n",
       "   'claim',\n",
       "   'is',\n",
       "   'true',\n",
       "   'may',\n",
       "   'depend',\n",
       "   'on',\n",
       "   'study',\n",
       "   'power',\n",
       "   'and',\n",
       "   'bias',\n",
       "   'the',\n",
       "   'number',\n",
       "   'of',\n",
       "   'other',\n",
       "   'studies',\n",
       "   'on',\n",
       "   'the',\n",
       "   'same',\n",
       "   'question',\n",
       "   'and',\n",
       "   'importantly',\n",
       "   'the',\n",
       "   'ratio',\n",
       "   'of',\n",
       "   'true',\n",
       "   'to',\n",
       "   'no',\n",
       "   'relationships',\n",
       "   'among',\n",
       "   'the',\n",
       "   'relationships',\n",
       "   'probed',\n",
       "   'in',\n",
       "   'each',\n",
       "   'scientific',\n",
       "   'field',\n",
       "   'in',\n",
       "   'this',\n",
       "   'framework',\n",
       "   'a',\n",
       "   'research',\n",
       "   'finding',\n",
       "   'is',\n",
       "   'less',\n",
       "   'likely',\n",
       "   'to',\n",
       "   'be',\n",
       "   'true',\n",
       "   'when',\n",
       "   'the',\n",
       "   'studies',\n",
       "   'conducted',\n",
       "   'in',\n",
       "   'a',\n",
       "   'field',\n",
       "   'are',\n",
       "   'when',\n",
       "   'effect',\n",
       "   'sizes',\n",
       "   'are',\n",
       "   'when',\n",
       "   'there',\n",
       "   'is',\n",
       "   'a',\n",
       "   'greater',\n",
       "   'number',\n",
       "   'and',\n",
       "   'lesser',\n",
       "   'preselection',\n",
       "   'of',\n",
       "   'tested',\n",
       "   'where',\n",
       "   'there',\n",
       "   'is',\n",
       "   'greater',\n",
       "   'flexibility',\n",
       "   'in',\n",
       "   'designs',\n",
       "   'definitions',\n",
       "   'outcomes',\n",
       "   'and',\n",
       "   'analytical',\n",
       "   'when',\n",
       "   'there',\n",
       "   'is',\n",
       "   'greater',\n",
       "   'financial',\n",
       "   'and',\n",
       "   'other',\n",
       "   'interest',\n",
       "   'and',\n",
       "   'and',\n",
       "   'when',\n",
       "   'more',\n",
       "   'teams',\n",
       "   'are',\n",
       "   'involved',\n",
       "   'in',\n",
       "   'a',\n",
       "   'scientific',\n",
       "   'field',\n",
       "   'in',\n",
       "   'chase',\n",
       "   'of',\n",
       "   'statistical',\n",
       "   'significance',\n",
       "   'simulations',\n",
       "   'show',\n",
       "   'that',\n",
       "   'for',\n",
       "   'most',\n",
       "   'study',\n",
       "   'designs',\n",
       "   'and',\n",
       "   'settings',\n",
       "   'it',\n",
       "   'is',\n",
       "   'more',\n",
       "   'likely',\n",
       "   'for',\n",
       "   'a',\n",
       "   'research',\n",
       "   'claim',\n",
       "   'to',\n",
       "   'be',\n",
       "   'false',\n",
       "   'than',\n",
       "   'true',\n",
       "   'moreover',\n",
       "   'for',\n",
       "   'many',\n",
       "   'current',\n",
       "   'scientific',\n",
       "   'fields',\n",
       "   'claimed',\n",
       "   'research',\n",
       "   'findings',\n",
       "   'may',\n",
       "   'often',\n",
       "   'be',\n",
       "   'simply',\n",
       "   'accurate',\n",
       "   'measures',\n",
       "   'of',\n",
       "   'the',\n",
       "   'prevailing',\n",
       "   'bias',\n",
       "   'in',\n",
       "   'this',\n",
       "   'essay',\n",
       "   'i',\n",
       "   'discuss',\n",
       "   'the',\n",
       "   'implications',\n",
       "   'of',\n",
       "   'these',\n",
       "   'problems',\n",
       "   'for',\n",
       "   'the',\n",
       "   'conduct',\n",
       "   'and',\n",
       "   'interpretation',\n",
       "   'of',\n",
       "   'research'])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Read the text file and create an RDD of lines\n",
    "papers_rdd = sc.textFile(\"papers.csv\")\n",
    "parsed_rdd = papers_rdd.map(lambda line: next(csv.reader([line])))\n",
    "\n",
    "# From each row in `parsed_rdd`, only take the first column, 'paper_id,' and the last column, 'abstract'\n",
    "extract_abstract_rdd = parsed_rdd.map(lambda row: (row[0],row[-1]))\n",
    "\n",
    "# Now, splitting the abstracts into a list of words (to be used later on), removing the punctuations, filtering out non-alpha characters, and caching the result to avoid re-computation.\n",
    "split_papers_rdd = extract_abstract_rdd.mapValues(lambda x: list(filter(None, re.split(\"[' ()}{,.?-]\", x))))\\\n",
    "                                       .mapValues(lambda x: [word for word in x if word.isalpha()]).cache()\n",
    "end_time = time.time()\n",
    "\n",
    "split_papers_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f962d80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in creating the pair RDD from `papaers.csv`: 0.08 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Time taken in creating the pair RDD from `papaers.csv`: %.2f seconds' % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c969044c",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Task 1.3 (Joining Collections)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd76127",
   "metadata": {},
   "source": [
    "**1.3.1 Getting stopwords and creating a broadcast variable to share between all workers of Spark cluster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a266387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'able', 'about', 'above', 'according', 'accordingly', 'across', 'actually', 'after', 'afterwards']\n"
     ]
    }
   ],
   "source": [
    "# Reading the stopwords from the file and storing them in a list\n",
    "with open('stopwords_en.txt', 'r') as file:\n",
    "    stopwords_list = [line.rstrip('\\n') for line in file]\n",
    "    print(stopwords_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff1874a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcast variable to share between all the workers in a Spark Cluster\n",
    "stop_word_rdd = sc.broadcast(stopwords_list)\n",
    "\n",
    "# This function would return a list of words that are not stop words\n",
    "# It iterates through the list of words and checking if each word is in the `stop_word_rdd` broadcast variable.\n",
    "# If the word is not in the broadcast variable, the function adds the word to the output list.\n",
    "def stopwords_filter(words_list):\n",
    "    return [word for word in words_list if word not in stop_word_rdd.value]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed253c60",
   "metadata": {},
   "source": [
    "**1.3.2 Computing the top-10 most frequent words appearing in the papers for each user**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddcebdf-1dea-4016-a55c-9bd04d6cbabc",
   "metadata": {},
   "source": [
    "***Method 01:*** Using cartesian product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c89dee4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('da593ecae187d0c4cfe01b7d8719d6e6',\n",
       "  ['health',\n",
       "   'mental',\n",
       "   'patient',\n",
       "   'image',\n",
       "   'literature',\n",
       "   'treatment',\n",
       "   'services',\n",
       "   'review',\n",
       "   'practice',\n",
       "   'systematic']),\n",
       " ('8b87ac1e5903e5af7dee9e54317f1a7c',\n",
       "  ['quantum',\n",
       "   'field',\n",
       "   'phase',\n",
       "   'state',\n",
       "   'states',\n",
       "   'theory',\n",
       "   'systems',\n",
       "   'experimental',\n",
       "   'single',\n",
       "   'spin']),\n",
       " ('7c5dcabf1ac0304dc89eec3ce3efe305',\n",
       "  ['path',\n",
       "   'routing',\n",
       "   'internet',\n",
       "   'avail',\n",
       "   'bw',\n",
       "   'switching',\n",
       "   'end',\n",
       "   'paths',\n",
       "   'quality',\n",
       "   'network']),\n",
       " ('4988459274c4c2daceb488b219bf9462',\n",
       "  ['protein',\n",
       "   'proteins',\n",
       "   'structure',\n",
       "   'structures',\n",
       "   'ribosome',\n",
       "   'translation',\n",
       "   'mrna',\n",
       "   'folding',\n",
       "   'resolution',\n",
       "   'membrane']),\n",
       " ('41a47ecde12a9c3c74d0994e0452da67',\n",
       "  ['software',\n",
       "   'suggests',\n",
       "   'computer',\n",
       "   'paper',\n",
       "   'soft',\n",
       "   'literature',\n",
       "   'paradigm',\n",
       "   'management',\n",
       "   'project',\n",
       "   'artifacts']),\n",
       " ('6519728d752a57e236943589f77068b5',\n",
       "  ['content',\n",
       "   'network',\n",
       "   'internet',\n",
       "   'information',\n",
       "   'centric',\n",
       "   'routing',\n",
       "   'data',\n",
       "   'based',\n",
       "   'networking',\n",
       "   'paper']),\n",
       " ('561f97cc6ca1c774c60bf3a8ed24ae3b',\n",
       "  ['language',\n",
       "   'knowledge',\n",
       "   'students',\n",
       "   'metalinguistic',\n",
       "   'proficiency',\n",
       "   'policies',\n",
       "   'linguistic',\n",
       "   'teaching',\n",
       "   'connections',\n",
       "   'define']),\n",
       " ('e453e82278f1cdff2add8c5db4a54636',\n",
       "  ['laws',\n",
       "   'social',\n",
       "   'systems',\n",
       "   'agent',\n",
       "   'agents',\n",
       "   'behaviour',\n",
       "   'multi',\n",
       "   'rational',\n",
       "   'basic',\n",
       "   'framework']),\n",
       " ('84c64f4615aec7fc860af211b5c331e7',\n",
       "  ['gene',\n",
       "   'expression',\n",
       "   'networks',\n",
       "   'genes',\n",
       "   'network',\n",
       "   'cell',\n",
       "   'cycle',\n",
       "   'states',\n",
       "   'data',\n",
       "   'model']),\n",
       " ('977e70bbc594469e3da77e48aaf53536',\n",
       "  ['gender',\n",
       "   'research',\n",
       "   'computer',\n",
       "   'sex',\n",
       "   'cmc',\n",
       "   'neuroticism',\n",
       "   'identity',\n",
       "   'digital',\n",
       "   'divide',\n",
       "   'personality']),\n",
       " ('4f1c6313872dd8fc0520c095f25ebf58',\n",
       "  ['wireless',\n",
       "   'channel',\n",
       "   'multiple',\n",
       "   'mimo',\n",
       "   'algorithm',\n",
       "   'users',\n",
       "   'capacity',\n",
       "   'data',\n",
       "   'signal',\n",
       "   'systems']),\n",
       " ('a467ac62f78ce131abcd6bcbca011de0',\n",
       "  ['users',\n",
       "   'recommender',\n",
       "   'user',\n",
       "   'systems',\n",
       "   'trust',\n",
       "   'based',\n",
       "   'recommendation',\n",
       "   'recommendations',\n",
       "   'system',\n",
       "   'social']),\n",
       " ('c1a435c2ce82e437d7abc46cb9632e80',\n",
       "  ['programming',\n",
       "   'language',\n",
       "   'register',\n",
       "   'code',\n",
       "   'based',\n",
       "   'data',\n",
       "   'algorithm',\n",
       "   'languages',\n",
       "   'systems',\n",
       "   'compiler']),\n",
       " ('b980fa2b04d991b7f024c59d70f04029',\n",
       "  ['data',\n",
       "   'spatial',\n",
       "   'model',\n",
       "   'analysis',\n",
       "   'ecological',\n",
       "   'methods',\n",
       "   'urban',\n",
       "   'management',\n",
       "   'research',\n",
       "   'policy']),\n",
       " ('fae6c0faf8220099a5e484ea5c92358b',\n",
       "  ['surface',\n",
       "   'polymer',\n",
       "   'nanocomposites',\n",
       "   'properties',\n",
       "   'structure',\n",
       "   'based',\n",
       "   'review',\n",
       "   'reviewed',\n",
       "   'applications',\n",
       "   'surfaces']),\n",
       " ('68a0dead14dc2b022b2a6a520a742cc8',\n",
       "  ['genetic',\n",
       "   'gene',\n",
       "   'data',\n",
       "   'approaches',\n",
       "   'pathway',\n",
       "   'gwa',\n",
       "   'based',\n",
       "   'el',\n",
       "   'phenotypic',\n",
       "   'function']),\n",
       " ('098b8e554ebf8333af3ab4edec0bf643',\n",
       "  ['binding',\n",
       "   'free',\n",
       "   'energy',\n",
       "   'molecular',\n",
       "   'protein',\n",
       "   'simulations',\n",
       "   'dynamics',\n",
       "   'force',\n",
       "   'ligand',\n",
       "   'methods']),\n",
       " ('e32f20b20e8c1932138c6629b25091a1',\n",
       "  ['wikipedia',\n",
       "   'information',\n",
       "   'collaborative',\n",
       "   'contribution',\n",
       "   'content',\n",
       "   'patterns',\n",
       "   'users',\n",
       "   'edit',\n",
       "   'show',\n",
       "   'pages']),\n",
       " ('b14298d045a83d8f25a0200053aa98d3',\n",
       "  ['binding',\n",
       "   'differences',\n",
       "   'ctcf',\n",
       "   'dna',\n",
       "   'epigenetic',\n",
       "   'chromatin',\n",
       "   'role',\n",
       "   'regulation',\n",
       "   'splicing',\n",
       "   'transcription']),\n",
       " ('11cda80a434cc05863609cbf7a23cb5c',\n",
       "  ['chi',\n",
       "   'square',\n",
       "   'signal',\n",
       "   'networks',\n",
       "   'degrees',\n",
       "   'freedom',\n",
       "   'energy',\n",
       "   'time',\n",
       "   'nodes',\n",
       "   'noncentral']),\n",
       " ('c1d2ccce7cec59d87b50c87b1acf60b7',\n",
       "  ['model',\n",
       "   'data',\n",
       "   'translation',\n",
       "   'language',\n",
       "   'lexicon',\n",
       "   'system',\n",
       "   'smt',\n",
       "   'adapted',\n",
       "   'algorithm',\n",
       "   'text']),\n",
       " ('00355a4db634da0aa1dee71b2633498d',\n",
       "  ['quantum',\n",
       "   'states',\n",
       "   'field',\n",
       "   'control',\n",
       "   'cavity',\n",
       "   'systems',\n",
       "   'optimal',\n",
       "   'state',\n",
       "   'gates',\n",
       "   'fidelity']),\n",
       " ('53efe55caa0078c49532e132018e6590',\n",
       "  ['divergence',\n",
       "   'confidence',\n",
       "   'time',\n",
       "   'interval',\n",
       "   'molecular',\n",
       "   'date',\n",
       "   'millions',\n",
       "   'multifactor',\n",
       "   'genes',\n",
       "   'years']),\n",
       " ('54be7b8c41efa49aa7b817bd4d278961',\n",
       "  ['design',\n",
       "   'game',\n",
       "   'designers',\n",
       "   'games',\n",
       "   'interaction',\n",
       "   'work',\n",
       "   'information',\n",
       "   'book',\n",
       "   'techniques',\n",
       "   'user']),\n",
       " ('edcb408400f6cc15047b7448e75ed757',\n",
       "  ['interaction',\n",
       "   'user',\n",
       "   'sensing',\n",
       "   'design',\n",
       "   'background',\n",
       "   'human',\n",
       "   'foreground',\n",
       "   'device',\n",
       "   'based',\n",
       "   'techniques']),\n",
       " ('b0c549749e46d2b9ea224b827b7ad380',\n",
       "  ['software',\n",
       "   'product',\n",
       "   'models',\n",
       "   'requirements',\n",
       "   'model',\n",
       "   'line',\n",
       "   'quality',\n",
       "   'feature',\n",
       "   'modeling',\n",
       "   'variability']),\n",
       " ('0ae795df6044b7428eeb73a7954832ed',\n",
       "  ['social',\n",
       "   'research',\n",
       "   'people',\n",
       "   'data',\n",
       "   'study',\n",
       "   'science',\n",
       "   'scale',\n",
       "   'scientific',\n",
       "   'findings',\n",
       "   'information']),\n",
       " ('f530323de681605b076b410f9d97e205',\n",
       "  ['gene',\n",
       "   'data',\n",
       "   'genes',\n",
       "   'expression',\n",
       "   'networks',\n",
       "   'function',\n",
       "   'based',\n",
       "   'biological',\n",
       "   'functional',\n",
       "   'methods']),\n",
       " ('61341b02b7c429e37f563d7c22f6df79',\n",
       "  ['women',\n",
       "   'project',\n",
       "   'discrimination',\n",
       "   'group',\n",
       "   'underrepresentation',\n",
       "   'learning',\n",
       "   'claims',\n",
       "   'current',\n",
       "   'based',\n",
       "   'science']),\n",
       " ('9f7c5193a50566f8099c6dc75ecc2f78',\n",
       "  ['network',\n",
       "   'virtualization',\n",
       "   'data',\n",
       "   'virtual',\n",
       "   'control',\n",
       "   'openflow',\n",
       "   'management',\n",
       "   'networks',\n",
       "   'performance',\n",
       "   'traffic']),\n",
       " ('1805d47f83451fc096fae76a4f69e70c',\n",
       "  ['model',\n",
       "   'space',\n",
       "   'sensor',\n",
       "   'networks',\n",
       "   'data',\n",
       "   'context',\n",
       "   'active',\n",
       "   'diffusion',\n",
       "   'entities',\n",
       "   'directed']),\n",
       " ('33af4c1148b5e5570784d6ff55c6eead',\n",
       "  ['genome',\n",
       "   'sequencing',\n",
       "   'data',\n",
       "   'chip',\n",
       "   'gene',\n",
       "   'sequence',\n",
       "   'high',\n",
       "   'small',\n",
       "   'expression',\n",
       "   'mirnas']),\n",
       " ('6b8ff5322acb2e77675dbb9b4ce760b6',\n",
       "  ['data',\n",
       "   'patients',\n",
       "   'mercury',\n",
       "   'sensor',\n",
       "   'collection',\n",
       "   'high',\n",
       "   'term',\n",
       "   'long',\n",
       "   'node',\n",
       "   'designed']),\n",
       " ('c883d180908d09eb241e4fc217280c2d',\n",
       "  ['network',\n",
       "   'social',\n",
       "   'model',\n",
       "   'theory',\n",
       "   'innovation',\n",
       "   'research',\n",
       "   'firms',\n",
       "   'firm',\n",
       "   'organizational',\n",
       "   'paper']),\n",
       " ('bc747f5fe98b75fa632ae2fd035ebf98',\n",
       "  ['drug',\n",
       "   'chinese',\n",
       "   'tacrolimus',\n",
       "   'polymorphisms',\n",
       "   'allele',\n",
       "   'recipients',\n",
       "   'frequencies',\n",
       "   'genotype',\n",
       "   'population',\n",
       "   'transplant']),\n",
       " ('e5b5e7cc457bdf16cf802cf3cdb20d88',\n",
       "  ['particle',\n",
       "   'review',\n",
       "   'tables',\n",
       "   'heavy',\n",
       "   'scalar',\n",
       "   'data',\n",
       "   'quark',\n",
       "   'glueball',\n",
       "   'results',\n",
       "   'Ï‡']),\n",
       " ('43019391243eda5c2a7454ba977400f5',\n",
       "  ['audio',\n",
       "   'method',\n",
       "   'classification',\n",
       "   'conjugate',\n",
       "   'based',\n",
       "   'mixed',\n",
       "   'methods',\n",
       "   'computer',\n",
       "   'learning',\n",
       "   'applications']),\n",
       " ('834cdfa6a29241902e985ded96d5b19f',\n",
       "  ['drug',\n",
       "   'data',\n",
       "   'drugs',\n",
       "   'genes',\n",
       "   'cancer',\n",
       "   'gene',\n",
       "   'disease',\n",
       "   'analysis',\n",
       "   'network',\n",
       "   'expression']),\n",
       " ('99bc89c49a693bc20844446c98a83f47',\n",
       "  ['sleep',\n",
       "   'children',\n",
       "   'problems',\n",
       "   'asd',\n",
       "   'parasomnias',\n",
       "   'disorder',\n",
       "   'epilepsy',\n",
       "   'age',\n",
       "   'daytime',\n",
       "   'insomnia']),\n",
       " ('21dc07b2205f3a703b93380a297bb3ed',\n",
       "  ['fading',\n",
       "   'rate',\n",
       "   'channel',\n",
       "   'wireless',\n",
       "   'performance',\n",
       "   'results',\n",
       "   'exor',\n",
       "   'networks',\n",
       "   'channels',\n",
       "   'multi']),\n",
       " ('25956cdc42b2d39411bf0165c9288e6a',\n",
       "  ['models',\n",
       "   'physics',\n",
       "   'tests',\n",
       "   'toolkit',\n",
       "   'matter',\n",
       "   'particles',\n",
       "   'complementary',\n",
       "   'simulating',\n",
       "   'current',\n",
       "   'provided']),\n",
       " ('2a2d42beabb3170c136746e67f1414e0',\n",
       "  ['statistics',\n",
       "   'book',\n",
       "   'bayesian',\n",
       "   'growth',\n",
       "   'empirical',\n",
       "   'nonresponse',\n",
       "   'treatment',\n",
       "   'graduate',\n",
       "   'methods',\n",
       "   'survey']),\n",
       " ('cbd0f26e0b615f1c14cf3b9224238286',\n",
       "  ['binding',\n",
       "   'chromatin',\n",
       "   'dna',\n",
       "   'genome',\n",
       "   'cell',\n",
       "   'data',\n",
       "   'tf',\n",
       "   'gene',\n",
       "   'transcription',\n",
       "   'cells']),\n",
       " ('38dd57bc49f780eeb30ccc846a53a9d5',\n",
       "  ['ppar',\n",
       "   'gamma',\n",
       "   'inflammatory',\n",
       "   'receptor',\n",
       "   'agonists',\n",
       "   'activated',\n",
       "   'effects',\n",
       "   'tzds',\n",
       "   'expression',\n",
       "   'shock']),\n",
       " ('4bd91ea216f4a66b77e94fd78d6c3575',\n",
       "  ['surface',\n",
       "   'molecules',\n",
       "   'layer',\n",
       "   'tunneling',\n",
       "   'molecular',\n",
       "   'graphene',\n",
       "   'structures',\n",
       "   'scanning',\n",
       "   'energy',\n",
       "   'interface']),\n",
       " ('46497d0275d802229bdaf4b317350017',\n",
       "  ['energies',\n",
       "   'functionals',\n",
       "   'density',\n",
       "   'functional',\n",
       "   'bond',\n",
       "   'basis',\n",
       "   'theory',\n",
       "   'set',\n",
       "   'dispersion',\n",
       "   'atoms']),\n",
       " ('e8d580ad47ac36b13e01d3738aebff77',\n",
       "  ['life',\n",
       "   'viruses',\n",
       "   'data',\n",
       "   'origin',\n",
       "   'education',\n",
       "   'evolution',\n",
       "   'learning',\n",
       "   'tree',\n",
       "   'cellular',\n",
       "   'model']),\n",
       " ('2d81d51d25eddaa1069e80adb8b50ae1',\n",
       "  ['chemotherapy',\n",
       "   'surgery',\n",
       "   'survival',\n",
       "   'adjuvant',\n",
       "   'patients',\n",
       "   'radiotherapy',\n",
       "   'death',\n",
       "   'cancer',\n",
       "   'meta',\n",
       "   'versus']),\n",
       " ('1799dca6c945f0f4a66271e00dd52032',\n",
       "  ['performance',\n",
       "   'counters',\n",
       "   'hardware',\n",
       "   'behavior',\n",
       "   'results',\n",
       "   'hpcs',\n",
       "   'predictors',\n",
       "   'time',\n",
       "   'stall',\n",
       "   'adaptive']),\n",
       " ('cb7abcbc34f3da35dbc17a0f8a2ccb71',\n",
       "  ['international',\n",
       "   'states',\n",
       "   'interests',\n",
       "   'actors',\n",
       "   'political',\n",
       "   'religious',\n",
       "   'social',\n",
       "   'article',\n",
       "   'realist',\n",
       "   'conflict'])]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Creating a new paper RDD by removing stopwords from earlier created papers RDD in 1.2 part (b)\n",
    "# paper_tuple[0] = paper_id\n",
    "# paper_tuple [1] = [list of abstract words in paper]\n",
    "papers_without_stopwords_rdd = split_papers_rdd.map(lambda paper_tuple: (paper_tuple[0], stopwords_filter(paper_tuple[1])))\n",
    "\n",
    "# Further filtering the papers_without_stopwords_rdd to ensure that only papers with abstract words as a list are included\n",
    "# So that we can take cartesian products between split_users_rdd where we have list of users with paper_id\n",
    "filtered_papers_without_stopwords_rdd = papers_without_stopwords_rdd.filter(lambda x: isinstance(x[1], list))\n",
    "\n",
    "# users_abstracts_rdd contains the users and the abstracts for the papers they have checked out. \n",
    "# The `cartesian()` transformation here creates a cartesian product of the `split_users_rdd` RDD and the `filtered_papers_without_stopwords_rdd` RDD.\n",
    "# So we have every possible combination of joining each user with each paper and their abstract.\n",
    "# The `filter()` transformation then applied to filter the cartesian product to only include users who have checked out papers that are in the `filtered_papers_without_stopwords_rdd` RDD. \n",
    "# The `map()` transformation is used to map filtered elements to a tuple of the user ID and the abstract for the paper. \n",
    "users_with_paper_abstracts_rdd = split_users_rdd.cartesian(filtered_papers_without_stopwords_rdd)\\\n",
    "                                    .filter(lambda x: x[1][0] in x[0][1])\\\n",
    "                                    .map(lambda x: (x[0][0],x[1][1])).cache()\n",
    "\n",
    "# The `reduceByKey()` transformation is then applied to reduce the `users_with_paper_abstracts_rdd` RDD by user ID, and to count the number of words in the abstracts for each user.\n",
    "users_words_rdd = users_with_paper_abstracts_rdd.reduceByKey(lambda x,y: x + y)\n",
    "\n",
    "# The`word_counts_rdd` RDD contains the users and the words that they have used in their abstracts. \n",
    "# Applying `flatMap()` transformation to flatten the `users_words_rdd` RDD. \n",
    "# The `reduceByKey()` transformation is used to reduce the `word_counts_rdd` RDD by user ID and to count the number of times each word appears in the abstracts for each user. \n",
    "# Then, `map()` transformation is used to map each element in the `word_counts_rdd` RDD to a tuple of the user ID and a list of the top 10 words that the user has used in their abstracts.\n",
    "word_counts_rdd = users_words_rdd.flatMap(lambda x: [((x[0], word), 1) for word in x[1]])\\\n",
    "                    .reduceByKey(lambda x, y: x+y)\\\n",
    "                    .map(lambda x: (x[0][0], [x[0][1],x[1]]))\n",
    "\n",
    "# `sorted_word_counts_rdd` RDD contains the users and the top 10 words that they have used in their abstracts. \n",
    "# The `groupByKey()` transformation is to group the `word_counts_rdd` RDD by user ID. \n",
    "# The `mapValues()` transformation then maps each group to a list of the top 10 words for the user. \n",
    "# `sorted()` function is used to sort the list of words by the number of times they appear. \n",
    "# `reverse=True` argument tells the `sorted()` function to sort the list in reverse order. \n",
    "# The `mapValues()` transformation is used to map each group to a list of the words in the group.\n",
    "sorted_word_counts_rdd = word_counts_rdd.groupByKey()\\\n",
    "                            .mapValues(lambda x: sorted(x, key=lambda x:x[1], reverse=True)[:10])\\\n",
    "                            .mapValues(lambda x: [z[0] for z in x])\n",
    "\n",
    "# Taking a random sample from the created `sorted_word_counts_rdd` to show each `user_id` with their top 10 words usage in abstracts.\n",
    "result = sorted_word_counts_rdd.takeSample(False, 50, 250)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ef21cce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to compute the top-10 most frequent words appearing in the papers for each user using cartesian product method: 3615.92 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Time taken to compute the top-10 most frequent words appearing in the papers for each user using cartesian product method: %.2f seconds' % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bbaf89",
   "metadata": {},
   "source": [
    "***Method 02:*** Using join function\n",
    "\n",
    "**<span style=\"color:red\">Note:</span>** Our first approach took a lot of time for calculation that's why we used another approach to optimise our first approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b39e76cb-f250-4db3-a150-3d3111790ee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3b07fa777afe1d573a80b86a684b6584',\n",
       "  ['applications',\n",
       "   'materials',\n",
       "   'devices',\n",
       "   'fabrication',\n",
       "   'mechanical',\n",
       "   'pdms',\n",
       "   'silver',\n",
       "   'actuator',\n",
       "   'properties',\n",
       "   'printed']),\n",
       " ('2a827b912e95043f5438835e4a82dcdd',\n",
       "  ['genetic',\n",
       "   'programming',\n",
       "   'problems',\n",
       "   'evolutionary',\n",
       "   'gene',\n",
       "   'networks',\n",
       "   'show',\n",
       "   'evolution',\n",
       "   'paper',\n",
       "   'search']),\n",
       " ('f6eb7bc494849bf723769935b8756cb7',\n",
       "  ['metabolic',\n",
       "   'microbial',\n",
       "   'models',\n",
       "   'communities',\n",
       "   'interactions',\n",
       "   'based',\n",
       "   'community',\n",
       "   'species',\n",
       "   'network',\n",
       "   'approach']),\n",
       " ('f40b76a7461831ece29917205e35d396',\n",
       "  ['social',\n",
       "   'child',\n",
       "   'awareness',\n",
       "   'research',\n",
       "   'practice',\n",
       "   'article',\n",
       "   'gender',\n",
       "   'relation',\n",
       "   'fathers',\n",
       "   'work']),\n",
       " ('db242f928ea40198cf01163dda7c7a1a',\n",
       "  ['bayesian',\n",
       "   'networks',\n",
       "   'causal',\n",
       "   'agent',\n",
       "   'based',\n",
       "   'simulation',\n",
       "   'services',\n",
       "   'probability',\n",
       "   'model',\n",
       "   'conservation']),\n",
       " ('28f2453b6a2a7a25061feb8b0f491969',\n",
       "  ['accessibility',\n",
       "   'web',\n",
       "   'users',\n",
       "   'guidelines',\n",
       "   'resources',\n",
       "   'authors',\n",
       "   'approaches',\n",
       "   'approach',\n",
       "   'people',\n",
       "   'conformance']),\n",
       " ('6710881a58ca0a157a372d83a3e19271',\n",
       "  ['dna',\n",
       "   'topoisomerase',\n",
       "   'cpt',\n",
       "   'adp',\n",
       "   'poly',\n",
       "   'enzyme',\n",
       "   'human',\n",
       "   'mutant',\n",
       "   'cleavage',\n",
       "   'residues']),\n",
       " ('3128e42a573c36d42e6cc8d1db30c627',\n",
       "  ['health',\n",
       "   'care',\n",
       "   'rural',\n",
       "   'mental',\n",
       "   'distress',\n",
       "   'psychological',\n",
       "   'anxiety',\n",
       "   'depression',\n",
       "   'primary',\n",
       "   'projects']),\n",
       " ('94466fd24fb5eea0ce14a727a3225feb',\n",
       "  ['methylation',\n",
       "   'cancer',\n",
       "   'gene',\n",
       "   'epigenetic',\n",
       "   'dna',\n",
       "   'breast',\n",
       "   'cpg',\n",
       "   'expression',\n",
       "   'genes',\n",
       "   'carcinoma']),\n",
       " ('ff2d92d99fe2383f4bbf345c9af31f37',\n",
       "  ['model',\n",
       "   'bayesian',\n",
       "   'models',\n",
       "   'methods',\n",
       "   'data',\n",
       "   'posterior',\n",
       "   'distribution',\n",
       "   'analysis',\n",
       "   'approach',\n",
       "   'statistical']),\n",
       " ('a9d8d4f9a1e016c6db17504397da3472',\n",
       "  ['data',\n",
       "   'gis',\n",
       "   'health',\n",
       "   'information',\n",
       "   'geographic',\n",
       "   'spatial',\n",
       "   'knowledge',\n",
       "   'research',\n",
       "   'analysis',\n",
       "   'geography']),\n",
       " ('03237605301d9dd8e883b91a7f0423de',\n",
       "  ['genes',\n",
       "   'gene',\n",
       "   'genome',\n",
       "   'data',\n",
       "   'sequences',\n",
       "   'small',\n",
       "   'analysis',\n",
       "   'mirnas',\n",
       "   'alignment',\n",
       "   'results']),\n",
       " ('f109992ad667b80194ae944b4e55be58',\n",
       "  ['behavior',\n",
       "   'behavioral',\n",
       "   'theory',\n",
       "   'dealing',\n",
       "   'control',\n",
       "   'means',\n",
       "   'perceived',\n",
       "   'intentions',\n",
       "   'relations',\n",
       "   'found']),\n",
       " ('10c53e0defeefeee4d3c5a2d5ac60541',\n",
       "  ['masses',\n",
       "   'rock',\n",
       "   'element',\n",
       "   'effects',\n",
       "   'dynamic',\n",
       "   'blast',\n",
       "   'process',\n",
       "   'numerical',\n",
       "   'loading',\n",
       "   'fracturing']),\n",
       " ('b581d9290069d82bdd5c65a1278c5eb8',\n",
       "  ['immigration',\n",
       "   'world',\n",
       "   'transparency',\n",
       "   'article',\n",
       "   'data',\n",
       "   'european',\n",
       "   'traditional',\n",
       "   'attitudes',\n",
       "   'circulation',\n",
       "   'newspaper']),\n",
       " ('3c236e9fa35b9c3793236eedae26124a',\n",
       "  ['survey',\n",
       "   'measures',\n",
       "   'digital',\n",
       "   'internet',\n",
       "   'article',\n",
       "   'instructional',\n",
       "   'media',\n",
       "   'online',\n",
       "   'findings',\n",
       "   'speaking']),\n",
       " ('18aa0bcb52597c1b8ed9f044fe3058ed',\n",
       "  ['web',\n",
       "   'knowledge',\n",
       "   'semantic',\n",
       "   'paper',\n",
       "   'large',\n",
       "   'annotation',\n",
       "   'world',\n",
       "   'retrieval',\n",
       "   'system',\n",
       "   'scale']),\n",
       " ('c5b1c0863a21c62fc92a72646bd41baa',\n",
       "  ['performance',\n",
       "   'applications',\n",
       "   'gpu',\n",
       "   'data',\n",
       "   'high',\n",
       "   'systems',\n",
       "   'system',\n",
       "   'router',\n",
       "   'parallel',\n",
       "   'memory']),\n",
       " ('0fdf83d9528c4492b616ebadc58facad',\n",
       "  ['language',\n",
       "   'syntactic',\n",
       "   'words',\n",
       "   'grammar',\n",
       "   'lexicon',\n",
       "   'system',\n",
       "   'lexical',\n",
       "   'memory',\n",
       "   'properties',\n",
       "   'subserved']),\n",
       " ('c1102f9f4b79bf1cd990a42e56d294f8',\n",
       "  ['civil',\n",
       "   'research',\n",
       "   'society',\n",
       "   'citizenship',\n",
       "   'libraries',\n",
       "   'digital',\n",
       "   'scientific',\n",
       "   'current',\n",
       "   'problems',\n",
       "   'discuss']),\n",
       " ('dc0b9b8ede410b41cf933611d55fe748',\n",
       "  ['workflow',\n",
       "   'knowledge',\n",
       "   'paper',\n",
       "   'strategies',\n",
       "   'systems',\n",
       "   'kqml',\n",
       "   'requirements',\n",
       "   'support',\n",
       "   'agent',\n",
       "   'agents']),\n",
       " ('1a43b9ae6fe5ab3014c3566e89bd373b',\n",
       "  ['type',\n",
       "   'language',\n",
       "   'semantics',\n",
       "   'programming',\n",
       "   'types',\n",
       "   'system',\n",
       "   'paper',\n",
       "   'proof',\n",
       "   'based',\n",
       "   'logic']),\n",
       " ('c36371eac0e77933b9987fb667dde775',\n",
       "  ['energy',\n",
       "   'dynamics',\n",
       "   'molecular',\n",
       "   'technique',\n",
       "   'simulation',\n",
       "   'sputtering',\n",
       "   'time',\n",
       "   'methods',\n",
       "   'ion',\n",
       "   'constant']),\n",
       " ('bd210c5fb5c0c6d2184fe80c9b3eb989',\n",
       "  ['dynamics',\n",
       "   'research',\n",
       "   'equation',\n",
       "   'orthants',\n",
       "   'scientific',\n",
       "   'boundary',\n",
       "   'true',\n",
       "   'correspond',\n",
       "   'study',\n",
       "   'problems']),\n",
       " ('d0963327543eaa37b69a8a36b9522163',\n",
       "  ['aortic',\n",
       "   'dissection',\n",
       "   'probability',\n",
       "   'pain',\n",
       "   'acute',\n",
       "   'variables',\n",
       "   'clinical',\n",
       "   'high',\n",
       "   'model',\n",
       "   'prediction']),\n",
       " ('67bf487ccd153ca5013b4dff9e720a64',\n",
       "  ['forced',\n",
       "   'blindsight',\n",
       "   'awareness',\n",
       "   'choice',\n",
       "   'detection',\n",
       "   'wagering',\n",
       "   'static',\n",
       "   'post',\n",
       "   'decisions',\n",
       "   'ncc']),\n",
       " ('571f742dc038650f64b912dec2f12b93',\n",
       "  ['dns',\n",
       "   'malware',\n",
       "   'approach',\n",
       "   'conficker',\n",
       "   'based',\n",
       "   'botgad',\n",
       "   'locator',\n",
       "   'hosts',\n",
       "   'mobile',\n",
       "   'network']),\n",
       " ('d4ea4976ce72f40f54cff3a7777cdf71',\n",
       "  ['memory',\n",
       "   'visual',\n",
       "   'capacity',\n",
       "   'cortex',\n",
       "   'working',\n",
       "   'wm',\n",
       "   'parietal',\n",
       "   'years',\n",
       "   'term',\n",
       "   'children']),\n",
       " ('30f5c9ccc6bf10d25e8cc52d36049165',\n",
       "  ['theory',\n",
       "   'control',\n",
       "   'results',\n",
       "   'area',\n",
       "   'experimental',\n",
       "   'waves',\n",
       "   'contained',\n",
       "   'theoretical',\n",
       "   'step',\n",
       "   'development']),\n",
       " ('8518f400ab5b78d4ad32aedd725ea9f6',\n",
       "  ['system',\n",
       "   'software',\n",
       "   'checkpointing',\n",
       "   'failures',\n",
       "   'error',\n",
       "   'systems',\n",
       "   'failure',\n",
       "   'based',\n",
       "   'analysis',\n",
       "   'performance']),\n",
       " ('ad71352a446b5c4d65054a18fdf5f753',\n",
       "  ['data',\n",
       "   'de',\n",
       "   'species',\n",
       "   'information',\n",
       "   'research',\n",
       "   'la',\n",
       "   'analysis',\n",
       "   'climate',\n",
       "   'change',\n",
       "   'biodiversity']),\n",
       " ('7efe4e643207a8ec91114359541ab817',\n",
       "  ['data',\n",
       "   'learning',\n",
       "   'algorithm',\n",
       "   'methods',\n",
       "   'em',\n",
       "   'likelihood',\n",
       "   'model',\n",
       "   'based',\n",
       "   'analysis',\n",
       "   'problems']),\n",
       " ('3e63b3a3f581a6748dc0667309c72536',\n",
       "  ['de',\n",
       "   'en',\n",
       "   'ns',\n",
       "   'da',\n",
       "   'os',\n",
       "   'se',\n",
       "   'profesionais',\n",
       "   'das',\n",
       "   'para',\n",
       "   'sanitarias']),\n",
       " ('1cfbd87283c6ddcfa1e3444fdd784277',\n",
       "  ['metabolomics',\n",
       "   'metabolic',\n",
       "   'metabolite',\n",
       "   'data',\n",
       "   'systems',\n",
       "   'analysis',\n",
       "   'potential',\n",
       "   'fingerprinting',\n",
       "   'field',\n",
       "   'biological']),\n",
       " ('77ecb574dc6c301e440dbc215767497b',\n",
       "  ['plagiarism',\n",
       "   'barriers',\n",
       "   'order',\n",
       "   'students',\n",
       "   'teachers',\n",
       "   'study',\n",
       "   'based',\n",
       "   'technology',\n",
       "   'effective',\n",
       "   'motor']),\n",
       " ('9ecf422500eefd727a482f2e06a13420',\n",
       "  ['disease',\n",
       "   'children',\n",
       "   'retinoblastoma',\n",
       "   'high',\n",
       "   'subsequent',\n",
       "   'radiation',\n",
       "   'term',\n",
       "   'rates',\n",
       "   'lead',\n",
       "   'child']),\n",
       " ('4726045b7ee205bb28034a0ad7b455a5',\n",
       "  ['model',\n",
       "   'cognitive',\n",
       "   'logic',\n",
       "   'based',\n",
       "   'systems',\n",
       "   'order',\n",
       "   'data',\n",
       "   'cognizers',\n",
       "   'cognition',\n",
       "   'system']),\n",
       " ('402674a0b4b2bec68695d93a3db7a696',\n",
       "  ['forest',\n",
       "   'biomass',\n",
       "   'plot',\n",
       "   'models',\n",
       "   'variables',\n",
       "   'data',\n",
       "   'mapping',\n",
       "   'rico',\n",
       "   'estimates',\n",
       "   'alaska']),\n",
       " ('f22ffa783cf6725682721d52e2ffbc0f',\n",
       "  ['research',\n",
       "   'scientific',\n",
       "   'biological',\n",
       "   'information',\n",
       "   'field',\n",
       "   'impact',\n",
       "   'systems',\n",
       "   'citation',\n",
       "   'structure',\n",
       "   'range']),\n",
       " ('325c36e7c44da36ac7b000c5d6af5c17',\n",
       "  ['clustering',\n",
       "   'data',\n",
       "   'problem',\n",
       "   'clusters',\n",
       "   'graph',\n",
       "   'algorithm',\n",
       "   'number',\n",
       "   'based',\n",
       "   'spectral',\n",
       "   'analysis']),\n",
       " ('28fbe054138f22960fc17a82c2b7e467',\n",
       "  ['response',\n",
       "   'bacterial',\n",
       "   'regulatory',\n",
       "   'bacteria',\n",
       "   'nutrient',\n",
       "   'phenotypic',\n",
       "   'evolution',\n",
       "   'function',\n",
       "   'chemotactic',\n",
       "   'chemoattractant']),\n",
       " ('b203f336b516777eba6d8bcc22c9c8f1',\n",
       "  ['scenario',\n",
       "   'quantitative',\n",
       "   'methods',\n",
       "   'foster',\n",
       "   'scenarios',\n",
       "   'resources',\n",
       "   'creativity',\n",
       "   'organizations',\n",
       "   'planning',\n",
       "   'qualitative']),\n",
       " ('4665c395ac29da4ad4e153a085221e03',\n",
       "  ['spreadsheets',\n",
       "   'spreadsheet',\n",
       "   'end',\n",
       "   'user',\n",
       "   'software',\n",
       "   'programming',\n",
       "   'users',\n",
       "   'evolution',\n",
       "   'approach',\n",
       "   'information']),\n",
       " ('1274967a2500e6741baf5ed2016741c3',\n",
       "  ['activity',\n",
       "   'physical',\n",
       "   'health',\n",
       "   'study',\n",
       "   'data',\n",
       "   'individuals',\n",
       "   'related',\n",
       "   'care',\n",
       "   'technology',\n",
       "   'results']),\n",
       " ('e798abbbebc3138eed3a2c42782c75d3',\n",
       "  ['situations',\n",
       "   'robot',\n",
       "   'tasks',\n",
       "   'learning',\n",
       "   'developmental',\n",
       "   'learn',\n",
       "   'coming',\n",
       "   'related',\n",
       "   'complex',\n",
       "   'show']),\n",
       " ('b69bf8f66c9384df3171b73318d810e5',\n",
       "  ['deception',\n",
       "   'emotional',\n",
       "   'brain',\n",
       "   'emotion',\n",
       "   'responses',\n",
       "   'participants',\n",
       "   'study',\n",
       "   'activity',\n",
       "   'lie',\n",
       "   'fmri']),\n",
       " ('18ea81094ee3c76bb07cec6c12ac9605',\n",
       "  ['network',\n",
       "   'performance',\n",
       "   'data',\n",
       "   'node',\n",
       "   'log',\n",
       "   'belt',\n",
       "   'nearest',\n",
       "   'time',\n",
       "   'algorithms',\n",
       "   'scientific']),\n",
       " ('290ae864c62bfb1e8fca118026df7a90',\n",
       "  ['user',\n",
       "   'interface',\n",
       "   'multimodal',\n",
       "   'context',\n",
       "   'task',\n",
       "   'users',\n",
       "   'interaction',\n",
       "   'interfaces',\n",
       "   'levels',\n",
       "   'design']),\n",
       " ('903bb79967e42c979a981e123711c627',\n",
       "  ['gang',\n",
       "   'prison',\n",
       "   'misconduct',\n",
       "   'gangs',\n",
       "   'threat',\n",
       "   'measure',\n",
       "   'members',\n",
       "   'street',\n",
       "   'prisons',\n",
       "   'forms']),\n",
       " ('6397fe3b048c2730ea4eac58328f5fe9',\n",
       "  ['human',\n",
       "   'genes',\n",
       "   'gene',\n",
       "   'coding',\n",
       "   'protein',\n",
       "   'genome',\n",
       "   'expression',\n",
       "   'transcripts',\n",
       "   'sequence',\n",
       "   'data'])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Creating a new paper RDD by removing stopwords from earlier created papers RDD in 1.2 part (b)\n",
    "# paper_tuple[0] = paper_id\n",
    "# paper_tuple [1] = [list of abstract words in paper]\n",
    "papers_without_stopwords_rdd = split_papers_rdd.map(lambda paper_tuple: (paper_tuple[0], stopwords_filter(paper_tuple[1])))\n",
    "\n",
    "# Further filtering the papers_without_stopwords_rdd to ensure that only papers with abstract words as a list are included\n",
    "# So that we can take cartesian products between split_users_rdd where we have list of users with paper_id\n",
    "filtered_papers_without_stopwords_rdd = papers_without_stopwords_rdd.filter(lambda x: isinstance(x[1], list))\n",
    "\n",
    "# `users_abstracts_rdd` RDD contains the users and the abstracts for the papers that they have checked out. [(paper_id, user_id),...]\n",
    "# The `flatMapValues()` transformation is used to flatten the `split_users_rdd` RDD\n",
    "# and then `map()` transformation is used to map each element in the `flatMapValues()` RDD to a tuple of the user ID and the abstract for the paper. \n",
    "# The `int()` function is used to convert the user ID to an integer.\n",
    "users_abstracts_rdd = split_users_rdd.flatMapValues(lambda x: x).map(lambda x: (int(x[1]),x[0]))\n",
    "\n",
    "# `filtered_papers_without_stopwords_rdd` has [(paper_id, abstract),...] so we join it directly with `users_abstracts_rdd` with [(paper_id, user_id),...]\n",
    "# As a result we get [(paper_id, user_id, [list of abstract words without stopwords]),...]\n",
    "users_papers_with_abstracts_rdd = users_abstracts_rdd.join(filtered_papers_without_stopwords_rdd)\n",
    "users_papers_with_abstracts_rdd.take(5)\n",
    "\n",
    "# The `map()` transformation creates each element in the `users_papers_with_abstracts_rdd` RDD to a tuple of the user ID and the abstract for the paper. \n",
    "users_abstracts_rdd = users_papers_with_abstracts_rdd.map(lambda x: (x[1][0], x[1][1]))\n",
    "users_abstracts_rdd.take(5)\n",
    "\n",
    "# `users_words_rdd` contains the words in the abstracts for the papers that the users have checked out. \n",
    "# `flatMapValues()` transformation further is used to flatten the `users_abstracts_rdd` RDD and\n",
    "# `map()` transformation is used to map each element in the `flatMapValues()` RDD to a tuple of the word and a count of 1 \n",
    "# Hence, `reduceByKey()` transformation is used to reduce the `users_words_rdd` RDD by word, and to count the number of times each word appears. \n",
    "# The `map()` transformation is used to map each element in the `reduceByKey()` RDD to a tuple of the user ID and a list of the words that the user has used in their abstracts. \n",
    "users_words_rdd = users_abstracts_rdd.flatMapValues(lambda x: x)\n",
    "users_words_counts = users_words_rdd.map(lambda x: (x,1)).reduceByKey(lambda x, y: x+y)\\\n",
    "                                  .map(lambda x: (x[0][0], [x[0][1],x[1]])).cache()\n",
    "\n",
    "# `sorted_word_counts_rdd` RDD contains the users and the top 10 words that they have used in their abstracts. \n",
    "# The `groupByKey()` transformation is to group the `word_counts_rdd` RDD by user ID. \n",
    "# The `mapValues()` transformation then maps each group to a list of the top 10 words for the user. \n",
    "# `sorted()` function is used to sort the list of words by the number of times they appear. \n",
    "# `reverse=True` argument tells the `sorted()` function to sort the list in reverse order. \n",
    "# The `mapValues()` transformation is used to map each group to a list of the words in the group.\n",
    "sorted_word_counts_rdd = users_words_counts.groupByKey()\\\n",
    "                            .mapValues(lambda x: sorted(x, key=lambda x:x[1], reverse=True)[:10])\\\n",
    "                            .mapValues(lambda x: [z[0] for z in x])\n",
    "\n",
    "result = sorted_word_counts_rdd.takeSample(False,50,250)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e323cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to compute the top-10 most frequent words appearing in the papers for each user using join function method: 414.56 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Time taken to compute the top-10 most frequent words appearing in the papers for each user using join function method: %.2f seconds' % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2132d61d-3514-46f6-b3b7-de3630f5b057",
   "metadata": {},
   "source": [
    "**1.3.3 Storing the the top-10 most frequent words appearing in the papers for each user in a text file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06764cfe-1a0e-40e9-9479-47ce82f8858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store_results_to_file, takes a list of tuples containing user hashes and lists of words.\n",
    "# It writes the user hash and its corresponding list of words to a file, with each entry on a new line.\n",
    "def store_results_to_file(user_top_10_words, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for user_hash, words_list in user_top_10_words:\n",
    "            line = f\"{user_hash}: {', '.join(words_list)}\\n\"\n",
    "            file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4ceb24a-cf7d-40a3-acc9-b3564dc7eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_results_to_file(result, \"user_top_frequent_words.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92648cc9",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Task 1.4 (Basic Analysis for Recommender Systems)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ce5ccf",
   "metadata": {},
   "source": [
    "**a) Number of (distinct) user, number of (distinct) items, and number of ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84bf3e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct users are 28416\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of distinct users are \" + str(split_users_rdd.map(lambda x: x[0]).distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eab02c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct papers are 172079\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of distinct papers/items are \" + str(split_papers_rdd.map(lambda x: x[0]).distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "568c9b9a-a56a-4903-96ec-663f2edfeabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct ratings is 828481\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of distinct ratings is \" + str(split_users_rdd.flatMap(lambda x: x[1]).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f643f-6f82-4430-9b5f-1b13274ba837",
   "metadata": {},
   "source": [
    "**b) Min number of ratings a user has given**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45aa246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The RDD contains the user IDs and the number of papers that each user has checked out. \n",
    "# The `mapValues()` transformation is used to map each element in the `split_users_rdd` RDD to the \n",
    "# length of the list of papers that the user has checked out. \n",
    "# The `cache()` transformation is used to cache the `users_stats` RDD.\n",
    "users_stats = split_users_rdd.mapValues(lambda x: len(x)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63562823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of ratings a user has given is 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Min number of ratings a user has given is \" + str(users_stats.map(lambda x: x[1]).min()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dad28f-8131-4d14-bc5d-ca18b4d49312",
   "metadata": {},
   "source": [
    "**c) Max number of ratings a user has given**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c7133d4-6c29-4587-9b77-8ea29d16e069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of ratings a user has given is 1922\n"
     ]
    }
   ],
   "source": [
    "print(\"Max number of ratings a user has given is \" + str(users_stats.map(lambda x: x[1]).max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddf60e8-74e7-4f6c-b0c0-9bf2492944cd",
   "metadata": {},
   "source": [
    "**d) Average number of ratings of users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef23012f-bc9d-40cb-9b22-8fe07e2ed26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of users ratings is 29.155440596846848\n"
     ]
    }
   ],
   "source": [
    "print(\"Average number of users ratings is \" + str(users_stats.map(lambda x: x[1]).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a31de-cb16-426d-97c5-5951c9aed330",
   "metadata": {},
   "source": [
    "**e) Standard deviation for ratings of users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45a9b720-cadb-4222-b892-1e5c3ddbb866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation for ratings of users is 81.1751761366871\n"
     ]
    }
   ],
   "source": [
    "print(\"Standard deviation for ratings of users is \" + str(users_stats.map(lambda x: x[1]).stdev()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115085a0-e777-4cd8-a0df-2a02aedfb3d5",
   "metadata": {},
   "source": [
    "**f) Min number of ratings an item has received**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb486ad5-a273-42d6-9c5a-e047abbd020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The RDD contains the paper IDs and the number of times each paper has been checked out. \n",
    "# The `flatMapValues()` transformation is used to flatten the `split_users_rdd` RDD. \n",
    "# The `map()` transformation is used to map each element in the `flatMapValues()` \n",
    "# RDD to a tuple of the paper ID and a count of 1. \n",
    "# `reduceByKey()` transformation is used to reduce the `papers_stats` RDD by paper ID, and to count the number of \n",
    "# times each paper appears. \n",
    "# The `cache()` transformation is used to cache the `papers_stats` RDD.\n",
    "papers_stats = split_users_rdd.flatMapValues(lambda x: x).map(lambda x: (x[1],1)).reduceByKey(lambda x,y: x+y).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "615316e8-093f-4f39-9200-e005b5fc2b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of ratings a user has given is 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Min number of ratings a user has given is \" + str(papers_stats.map(lambda x: x[1]).min()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff58da7-0f13-42d6-9ce9-88ffc499fa92",
   "metadata": {},
   "source": [
    "**g) Max number of ratings an item has received**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d58c20bc-5138-40d4-b734-10b2142d9d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of ratings a user has given is 924\n"
     ]
    }
   ],
   "source": [
    "print(\"Max number of ratings a user has given is \" + str(papers_stats.map(lambda x: x[1]).max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6278b3-271b-4f51-8505-07ae1005c4b6",
   "metadata": {},
   "source": [
    "**h) Average number of ratings of items**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98e78624-58fc-4fda-b9b9-e50b2e11efc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of users ratings is 4.814538671191683\n"
     ]
    }
   ],
   "source": [
    "print(\"Average number of users ratings is \" + str(papers_stats.map(lambda x: x[1]).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc37ba49-9e64-453c-b33c-6b8d0f21e3f7",
   "metadata": {},
   "source": [
    "**i) Standard deviation for ratings of items**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9741ae8-5af5-424c-b0f9-a41fe96fc05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation for ratings of users is 5.477802292314591\n"
     ]
    }
   ],
   "source": [
    "print(\"Standard deviation for ratings of users is \" + str(papers_stats.map(lambda x: x[1]).stdev()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f423e4",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Task 1.5 (Loading the dataset into Data Frames)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e86afa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank, col, explode, split, udf, row_number\n",
    "from pyspark.sql.types import ArrayType, IntegerType, StringType\n",
    "from pyspark.sql.functions import sum, avg, max, min, stddev, count, countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b8c2408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a SparkSession with a similar configuration as in Task 1.2\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LocalSparkCluster\") \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Accessing the SparkContext \n",
    "sc_df = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49bbe9e-4c73-49ae-8f9e-68f8f7c0e7d3",
   "metadata": {},
   "source": [
    "**Creating papersDataFrame with suitable schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db2ead6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|paper_id|            abstract|\n",
      "+--------+--------------------+\n",
      "|   80546|the genetic code ...|\n",
      "| 5842862|choosing good pro...|\n",
      "| 1242600|although scientis...|\n",
      "| 3467077|\"many scientists ...|\n",
      "|  309395|there is increasi...|\n",
      "+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "papers_schema = \"`paper_id` INT, `type` STRING, `journal` STRING, `bookÙ€title` STRING, `series` STRING, `publisher` STRING, \\\n",
    "                `pages` INT, `volume` INT, `number` INT, `year` INT, `month` STRING, `postedat` STRING, `address` STRING, \\\n",
    "                `title` STRING, `abstract` STRING\"\n",
    "\n",
    "# The DataFrame contains the paper IDs and abstracts from the `papers.csv` file. \n",
    "papers_df = spark.read.csv('papers.csv', header=False, schema=papers_schema)['paper_id','abstract']\n",
    "papers_df.show(5,truncate=True)\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "46ba3125-0995-49ec-8919-337f6bb792a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in creating the papers DataFrame from user `papers.csv`: 0.18 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Time taken in creating the papers DataFrame from user `papers.csv`: %.2f seconds' % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1e2fd7-a502-487d-931a-1cbefb543d35",
   "metadata": {},
   "source": [
    "**Creating usersLibraryDataFrame with suitable schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d573f623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|             user_id|              papers|\n",
      "+--------------------+--------------------+\n",
      "|28d3f81251d94b097...|[3929762, 503574,...|\n",
      "|d0c9aaa788153daea...|[2080631, 6343346...|\n",
      "|f05bcffe7951de9e5...|[1158654, 478707,...|\n",
      "|ca4f1ba4094011d9a...|            [278019]|\n",
      "|d1d41a15201915503...|[6610569, 6493797...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "users_library_schema = \"`user_id` STRING, `papers` STRING\"\n",
    "\n",
    "users_library_df = spark.read.csv(\"users_libraries.txt\", header=False, sep=\";\", schema=users_library_schema)\n",
    "users_library_df = users_library_df.withColumn(\"papers\", split(users_library_df.papers, ',').cast(ArrayType(IntegerType())))\n",
    "users_library_df.show(5,truncate=True)\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "85e89652-2435-4d15-982e-70cefbfa40dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in creating the users DataFrame from user `users_libraries.txt`: 0.16 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Time taken in creating the users DataFrame from user `users_libraries.txt`: %.2f seconds' % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd70d40",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Task 1.6 (Tasks on top of DataFrames)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3730c66-b242-4ba0-880d-295058a8f871",
   "metadata": {},
   "source": [
    "**Replicating Task 1.3 using Spark DataFrames**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8443310-300d-4e46-86d6-d89ecfb47125",
   "metadata": {},
   "source": [
    "***1.3.1 Getting stopwords and creating a broadcast variable to share between all workers of Spark cluster***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d76ed133-84ef-46e0-8120-94d45ebf265e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'able', 'about', 'above', 'according', 'accordingly', 'across', 'actually', 'after', 'afterwards']\n"
     ]
    }
   ],
   "source": [
    "# Reading the stopwords from the file and storing them in a list\n",
    "with open('stopwords_en.txt', 'r') as file:\n",
    "    stopwords_list = [line.rstrip('\\n') for line in file]\n",
    "    print(stopwords_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "398da462-fb6b-493d-8ad7-4e93ac651558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcast variable to share between all the workers in a Spark Cluster\n",
    "stop_word_rdd = sc_df.broadcast(stopwords_list)\n",
    "\n",
    "# This function would return a list of words that are not stop words\n",
    "# It iterates through the list of words and checking if each word is in the `stop_word_rdd` broadcast variable.\n",
    "# If the word is not in the broadcast variable, the function adds the word to the output list.\n",
    "def stopwords_filter(words_list):\n",
    "    return [word for word in words_list if word not in stop_word_rdd.value]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd08457-0008-4da1-9961-fcf36f7c5900",
   "metadata": {},
   "source": [
    "***1.3.2 Computing the top-10 most frequent words appearing in the papers for each user***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76fbdbe6-f5fb-4677-a616-f1873f2bbed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|paper_id|            abstract|\n",
      "+--------+--------------------+\n",
      "|   80546|[genetic, code, r...|\n",
      "| 5842862|[choosing, good, ...|\n",
      "| 1242600|[scientists, typi...|\n",
      "| 3467077|[scientists, mana...|\n",
      "|  309395|[increasing, conc...|\n",
      "+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The function processes the paper abstract to remove all the stopwords from them\n",
    "def abstract_processing(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    words = re.split(\"[' ()}{,.?-]\", x)\n",
    "    words = [word for word in words if word not in stop_word_rdd.value]\n",
    "    return list(filter(str.isalpha, words))\n",
    "\n",
    "# The `split_function` is the UDF(User Defined Function) to be used in Spark for removing stop-words from the papers.\n",
    "split_function = udf(abstract_processing, ArrayType(StringType()))\n",
    "\n",
    "# Using the `withColumn()` function to take the name of the new column and the UDF that we defined is used here to calculate the value of the new column.\n",
    "papers_df = papers_df.withColumn(\"abstract\", split_function(col(\"abstract\")))\n",
    "papers_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f109f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|             user_id| papers|\n",
      "+--------------------+-------+\n",
      "|28d3f81251d94b097...|3929762|\n",
      "|28d3f81251d94b097...| 503574|\n",
      "|28d3f81251d94b097...|5819422|\n",
      "|28d3f81251d94b097...|4238883|\n",
      "|28d3f81251d94b097...|5788061|\n",
      "+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a new column called `papers` in the `users_library_df` DataFrame. \n",
    "# Then using the `explode()` function to expand the list into rows \n",
    "users_paper_pair = users_library_df.withColumn(\"papers\", explode(users_library_df.papers))\n",
    "users_paper_pair.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7cc328f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+-----+-------+\n",
      "|             user_id|abstract_words|count|ranking|\n",
      "+--------------------+--------------+-----+-------+\n",
      "|00095808cdc611fb5...|        errors|    5|      1|\n",
      "|00095808cdc611fb5...|          text|    3|      2|\n",
      "|00095808cdc611fb5...|   information|    3|      3|\n",
      "|00095808cdc611fb5...|        impact|    2|      4|\n",
      "|00095808cdc611fb5...|           web|    2|      5|\n",
      "|00095808cdc611fb5...|          list|    2|      6|\n",
      "|00095808cdc611fb5...|    department|    2|      7|\n",
      "|00095808cdc611fb5...|   recognition|    2|      8|\n",
      "|00095808cdc611fb5...| automatically|    2|      9|\n",
      "|00095808cdc611fb5...|         error|    2|     10|\n",
      "|00095808cdc611fb5...|          site|    2|     11|\n",
      "|00095808cdc611fb5...|          data|    2|     12|\n",
      "|00095808cdc611fb5...|     character|    2|     13|\n",
      "|00095808cdc611fb5...|       problem|    2|     14|\n",
      "|00095808cdc611fb5...|      analyzed|    1|     15|\n",
      "|00095808cdc611fb5...|       induced|    1|     16|\n",
      "|00095808cdc611fb5...|      paradigm|    1|     17|\n",
      "|00095808cdc611fb5...|      involved|    1|     18|\n",
      "|00095808cdc611fb5...|         apply|    1|     19|\n",
      "|00095808cdc611fb5...|          part|    1|     20|\n",
      "+--------------------+--------------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Using the `inner` join here for `users_paper_pair` and `papers_df` \n",
    "# to to ensure that only rows that exist in both DataFrames are included in the result.\n",
    "users_abstract = users_paper_pair.join(papers_df, users_paper_pair.papers ==  papers_df.paper_id,\"inner\")\n",
    "\n",
    "# The `abstract_words` column in the `users_abstract_words` DataFrame will contain a single row for each word in the abstracts for the papers that a user has liked.\n",
    "users_abstract_words = users_abstract.withColumn(\"abstract_words\", explode(col(\"abstract\")))['user_id','abstract_words']\n",
    "\n",
    "# Now grouping the `user_id` and the `abstract_words` to perform `count()` aggregation function \n",
    "# to count the number of times each word appears in the abstracts for the papers that a user likes.\n",
    "users_words_count = users_abstract_words.groupBy(\"user_id\", \"abstract_words\").count()\n",
    "\n",
    "# Using window partition on the `users_words_count` DataFrame by the user ID to group it. \n",
    "# Then ordering to order the rows in the window partition by the `count` column in descending order.\n",
    "windowPartition = Window.partitionBy(\"user_id\").orderBy(col(\"count\").desc())\n",
    "\n",
    "# Adding a new column `ranking` to the `users_words_count` DataFrame. \n",
    "# Using `row_number()` function then for ranking to each row in the window partition.\n",
    "# @NOTE: Using ranking by the count column\n",
    "users_words_count = users_words_count.withColumn(\"ranking\", row_number().over(windowPartition))\n",
    "\n",
    "users_words_count.show()\n",
    "\n",
    "endtime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0a806966-5181-46f1-80e1-9fe798bcfba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in showing the words count: 96.99 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Time taken in showing the words count: %.2f seconds' % (endtime - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfc84511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+-----+-------+\n",
      "|             user_id|abstract_words|count|ranking|\n",
      "+--------------------+--------------+-----+-------+\n",
      "|00095808cdc611fb5...|        errors|    5|      1|\n",
      "|00095808cdc611fb5...|          text|    3|      2|\n",
      "|00095808cdc611fb5...|   information|    3|      3|\n",
      "|00095808cdc611fb5...|        impact|    2|      4|\n",
      "|00095808cdc611fb5...|           web|    2|      5|\n",
      "|00095808cdc611fb5...|          list|    2|      6|\n",
      "|00095808cdc611fb5...|    department|    2|      7|\n",
      "|00095808cdc611fb5...|   recognition|    2|      8|\n",
      "|00095808cdc611fb5...| automatically|    2|      9|\n",
      "|00095808cdc611fb5...|         error|    2|     10|\n",
      "|000ac87bf9c1623ee...| consciousness|   14|      1|\n",
      "|000ac87bf9c1623ee...|         place|    2|      2|\n",
      "|000ac87bf9c1623ee...|       mystery|    2|      3|\n",
      "|000ac87bf9c1623ee...|       account|    2|      4|\n",
      "|000ac87bf9c1623ee...|         world|    2|      5|\n",
      "|000ac87bf9c1623ee...|       problem|    2|      6|\n",
      "|000ac87bf9c1623ee...|        theory|    2|      7|\n",
      "|000ac87bf9c1623ee...|          book|    2|      8|\n",
      "|000ac87bf9c1623ee...|        mental|    2|      9|\n",
      "|000ac87bf9c1623ee...|         kinds|    2|     10|\n",
      "+--------------------+--------------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing the top-10 most frequent words appearing in the papers for each user\n",
    "result = users_words_count.filter(col(\"ranking\") <= 10)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e5d2ab-d9f7-41e9-ac4f-e805bce1ad18",
   "metadata": {},
   "source": [
    "***1.3.3 Storing the result of top-10 most frequent words appearing in the papers for each user in a text file***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "601a8eab-7210-4f8c-af3d-ba3d4b9d8695",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write.csv('user_top_frequent_words_using_df', header=True, mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8f641b-3f62-438d-a605-10dd655d34fe",
   "metadata": {},
   "source": [
    "**Replicating Task 1.4 using Spark DataFrames**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b043c6-ce69-47ef-a75e-29b476903886",
   "metadata": {},
   "source": [
    "***a) Number of (distinct) user, number of (distinct) items, and number of ratings***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3e4ed5e-ad33-4c08-b28c-b93cd88c8972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct users are 28416\n"
     ]
    }
   ],
   "source": [
    "distinct_user_count = users_library_df.select(countDistinct(\"user_id\")).collect()[0][0]\n",
    "print(\"Number of distinct users are \" + str(distinct_user_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a4b3c8-73cf-4de9-ade9-8138e82fc78d",
   "metadata": {},
   "source": [
    "***b) Min number of ratings a user has given***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12743e5f-97a4-4aef-8251-8811183a0107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|min(no_papers)|\n",
      "+--------------+\n",
      "|             1|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_papers = udf(lambda x: len(x), IntegerType())\n",
    "users_stats_df = users_library_df.withColumn(\"no_papers\", number_of_papers(col(\"papers\")))\n",
    "users_stats_df.agg(min(\"no_papers\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f6de4-04ff-4eb2-962d-5c71603d340f",
   "metadata": {},
   "source": [
    "***c) Max number of ratings a user has given***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "453b0cd9-b035-4e5e-a629-4bf804d5b9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|max(no_papers)|\n",
      "+--------------+\n",
      "|          1922|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_stats_df.agg(max(\"no_papers\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d992b93-4416-4c6d-8854-263bb2cbb365",
   "metadata": {},
   "source": [
    "***d) Average number of ratings of users***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a10f3893-1718-4380-b6f6-0f972163b76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|    avg(no_papers)|\n",
      "+------------------+\n",
      "|29.155440596846848|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_stats_df.agg(avg(\"no_papers\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370f11a-23d3-473d-815c-9dc7a7b2a14b",
   "metadata": {},
   "source": [
    "***e) Standard deviation for ratings of users***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a815a89d-09a5-4548-b441-251d65fbf7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|stddev_samp(no_papers)|\n",
      "+----------------------+\n",
      "|     81.17660451011594|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_stats_df.agg(stddev(\"no_papers\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c6e67a-0787-494f-adf7-299a29eeec54",
   "metadata": {},
   "source": [
    "***f) Min number of ratings an item has received***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "605541b6-6564-4515-bb6a-f4b0abce2284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|min(paper_count)|\n",
      "+----------------+\n",
      "|               3|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paper_counts = users_paper_pair.distinct().groupBy(\"papers\").agg(count(\"*\").alias(\"paper_count\"))\n",
    "paper_counts.agg(min(\"paper_count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1de13fa-20f1-48ca-ba4f-e9458486eb55",
   "metadata": {},
   "source": [
    "***g) Max number of ratings an item has received***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc50bd56-38b7-4a3d-9114-26331e1aed39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|max(paper_count)|\n",
      "+----------------+\n",
      "|             924|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paper_counts.agg(max(\"paper_count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe8e65-ba76-4147-a8db-ad7da12cfcb7",
   "metadata": {},
   "source": [
    "***h) Average number of ratings of items***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b391a582-0e66-437c-b2f2-623a34efc9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|avg(paper_count)|\n",
      "+----------------+\n",
      "|4.81453867119172|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paper_counts.agg(avg(\"paper_count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7af09-8a3c-478b-8994-8d996b451e00",
   "metadata": {},
   "source": [
    "***i) Standard deviation for ratings of items***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "211123f1-c243-45b8-9f09-c2675c208115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|stddev_samp(paper_count)|\n",
      "+------------------------+\n",
      "|       5.477818208917296|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paper_counts.agg(stddev(\"paper_count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8a99dc-4a08-4205-a8f2-33c720cf5172",
   "metadata": {},
   "source": [
    "**Performance difference between RDDs and DataFrames**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a7bb1-97e9-4d0d-a2a6-4f3522531925",
   "metadata": {},
   "source": [
    "**1. Execution time in seconds for creating Data Models**:\n",
    "\n",
    "* Pair RDD for 'users_libraries.txt': 0.08 seconds\n",
    "* DataFrame for 'users_libraries.txt': 0.18 seconds\n",
    "----------------------------------------\n",
    "* Pair RDD for 'papers.csv': 0.08 seconds\n",
    "* DataFrame for 'papers.csv': 0.16 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68a18a6-ab74-4a34-97fa-32bdbf643693",
   "metadata": {},
   "source": [
    "**2. Execution time in seconds for finding top 10 frequent words in each paper by the user**:\n",
    "\n",
    "* Using RDD (Cartesian method): 3615.92 seconds\n",
    "* Using RDD (Join method): 414.56 seconds\n",
    "----------------------------------------\n",
    "* Using Dataframes: 96.99 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ef9873-3db4-4897-9180-de0e315af1df",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Note:** </span>Since it was structured data, so using DataFrames have given better performance while performing the experiments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
